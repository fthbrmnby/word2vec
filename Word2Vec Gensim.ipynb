{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sentence(object):\n",
    "    \"\"\" Setup an iterator which cycle through the data \n",
    "    without having to load the entire data set into memory.\n",
    "    This is vital, as some text data sets are huge \"\"\"\n",
    "    \n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for file_name in os.listdir(self.dirname):\n",
    "            with open(os.path.join(self.dirname, file_name), 'r') as f:\n",
    "                for word in f.read().split():\n",
    "                    yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentences = word2vec.Text8Corpus('text')\n",
    "path = \"processed_text_data/text\"\n",
    "sentences = word2vec.LineSentence(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-25 12:40:59,581 : INFO : collecting all words and their counts\n",
      "2018-05-25 12:41:00,757 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-05-25 12:41:03,456 : INFO : collected 302084 word types from a corpus of 10346611 raw words and 1035 sentences\n",
      "2018-05-25 12:41:03,457 : INFO : Loading a fresh vocabulary\n",
      "2018-05-25 12:41:03,643 : INFO : min_count=20 retains 39233 unique words (12% of original 302084, drops 262851)\n",
      "2018-05-25 12:41:03,643 : INFO : min_count=20 leaves 9432604 word corpus (91% of original 10346611, drops 914007)\n",
      "2018-05-25 12:41:03,750 : INFO : deleting the raw counts dictionary of 302084 items\n",
      "2018-05-25 12:41:03,810 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2018-05-25 12:41:03,811 : INFO : downsampling leaves estimated 8854970 word corpus (93.9% of prior 9432604)\n",
      "2018-05-25 12:41:03,945 : INFO : estimated required memory for 39233 words and 300 dimensions: 113775700 bytes\n",
      "2018-05-25 12:41:03,945 : INFO : resetting layer weights\n",
      "2018-05-25 12:41:04,407 : INFO : training model with 4 workers on 39233 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-05-25 12:41:05,550 : INFO : EPOCH 1 - PROGRESS: at 0.10% examples, 7737 words/s, in_qsize 5, out_qsize 2\n",
      "2018-05-25 12:41:06,599 : INFO : EPOCH 1 - PROGRESS: at 6.38% examples, 266937 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:41:07,606 : INFO : EPOCH 1 - PROGRESS: at 13.62% examples, 391074 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:08,615 : INFO : EPOCH 1 - PROGRESS: at 20.87% examples, 455052 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:09,623 : INFO : EPOCH 1 - PROGRESS: at 28.12% examples, 489437 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:10,636 : INFO : EPOCH 1 - PROGRESS: at 35.46% examples, 512930 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:11,642 : INFO : EPOCH 1 - PROGRESS: at 42.80% examples, 528968 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:12,647 : INFO : EPOCH 1 - PROGRESS: at 49.95% examples, 541102 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:13,650 : INFO : EPOCH 1 - PROGRESS: at 57.10% examples, 550927 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:14,658 : INFO : EPOCH 1 - PROGRESS: at 63.77% examples, 554026 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-25 12:41:15,672 : INFO : EPOCH 1 - PROGRESS: at 69.86% examples, 552250 words/s, in_qsize 8, out_qsize 1\n",
      "2018-05-25 12:41:16,681 : INFO : EPOCH 1 - PROGRESS: at 76.91% examples, 556993 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:17,691 : INFO : EPOCH 1 - PROGRESS: at 84.15% examples, 563025 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:18,703 : INFO : EPOCH 1 - PROGRESS: at 90.92% examples, 565008 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:41:19,717 : INFO : EPOCH 1 - PROGRESS: at 98.07% examples, 567851 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:20,192 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-25 12:41:20,194 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 12:41:20,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 12:41:20,214 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 12:41:20,215 : INFO : EPOCH - 1 : training on 10346611 raw words (8854537 effective words) took 15.8s, 560192 effective words/s\n",
      "2018-05-25 12:41:21,449 : INFO : EPOCH 2 - PROGRESS: at 0.10% examples, 7204 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:22,450 : INFO : EPOCH 2 - PROGRESS: at 6.18% examples, 254407 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:23,458 : INFO : EPOCH 2 - PROGRESS: at 12.66% examples, 358882 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:24,464 : INFO : EPOCH 2 - PROGRESS: at 17.58% examples, 380247 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:25,477 : INFO : EPOCH 2 - PROGRESS: at 21.93% examples, 382369 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:26,499 : INFO : EPOCH 2 - PROGRESS: at 28.21% examples, 407850 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:27,511 : INFO : EPOCH 2 - PROGRESS: at 35.07% examples, 433501 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:28,514 : INFO : EPOCH 2 - PROGRESS: at 41.84% examples, 451692 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:29,522 : INFO : EPOCH 2 - PROGRESS: at 48.89% examples, 469188 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:30,536 : INFO : EPOCH 2 - PROGRESS: at 55.65% examples, 481276 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-25 12:41:31,549 : INFO : EPOCH 2 - PROGRESS: at 62.61% examples, 492246 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:32,565 : INFO : EPOCH 2 - PROGRESS: at 69.47% examples, 501154 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:33,577 : INFO : EPOCH 2 - PROGRESS: at 75.94% examples, 505371 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:34,583 : INFO : EPOCH 2 - PROGRESS: at 80.97% examples, 501082 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:35,598 : INFO : EPOCH 2 - PROGRESS: at 86.57% examples, 500130 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:36,617 : INFO : EPOCH 2 - PROGRESS: at 92.27% examples, 499866 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:37,864 : INFO : EPOCH 2 - PROGRESS: at 98.84% examples, 496428 words/s, in_qsize 8, out_qsize 2\n",
      "2018-05-25 12:41:38,041 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-25 12:41:38,046 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 12:41:38,060 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 12:41:38,066 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 12:41:38,067 : INFO : EPOCH - 2 : training on 10346611 raw words (8854050 effective words) took 17.8s, 496166 effective words/s\n",
      "2018-05-25 12:41:39,319 : INFO : EPOCH 3 - PROGRESS: at 0.10% examples, 7062 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:40,333 : INFO : EPOCH 3 - PROGRESS: at 6.47% examples, 262294 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:41,346 : INFO : EPOCH 3 - PROGRESS: at 13.82% examples, 387038 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:42,348 : INFO : EPOCH 3 - PROGRESS: at 21.06% examples, 451509 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:43,349 : INFO : EPOCH 3 - PROGRESS: at 28.31% examples, 486613 words/s, in_qsize 8, out_qsize 1\n",
      "2018-05-25 12:41:44,353 : INFO : EPOCH 3 - PROGRESS: at 35.65% examples, 511059 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:45,359 : INFO : EPOCH 3 - PROGRESS: at 42.03% examples, 516055 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:46,363 : INFO : EPOCH 3 - PROGRESS: at 48.99% examples, 527272 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:47,367 : INFO : EPOCH 3 - PROGRESS: at 55.36% examples, 531122 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:48,372 : INFO : EPOCH 3 - PROGRESS: at 62.61% examples, 541265 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:49,382 : INFO : EPOCH 3 - PROGRESS: at 69.18% examples, 544558 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:41:50,392 : INFO : EPOCH 3 - PROGRESS: at 76.52% examples, 551916 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:51,394 : INFO : EPOCH 3 - PROGRESS: at 83.00% examples, 553560 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:52,409 : INFO : EPOCH 3 - PROGRESS: at 88.60% examples, 548876 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:41:53,426 : INFO : EPOCH 3 - PROGRESS: at 95.36% examples, 551181 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:41:54,348 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-25 12:41:54,360 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 12:41:54,363 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 12:41:54,368 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 12:41:54,369 : INFO : EPOCH - 3 : training on 10346611 raw words (8854267 effective words) took 16.3s, 543250 effective words/s\n",
      "2018-05-25 12:41:55,602 : INFO : EPOCH 4 - PROGRESS: at 0.10% examples, 7217 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:56,607 : INFO : EPOCH 4 - PROGRESS: at 6.09% examples, 250112 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:57,646 : INFO : EPOCH 4 - PROGRESS: at 10.92% examples, 306171 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-25 12:41:58,659 : INFO : EPOCH 4 - PROGRESS: at 17.00% examples, 364295 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:41:59,672 : INFO : EPOCH 4 - PROGRESS: at 23.96% examples, 413133 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:00,696 : INFO : EPOCH 4 - PROGRESS: at 30.53% examples, 437333 words/s, in_qsize 8, out_qsize 1\n",
      "2018-05-25 12:42:01,717 : INFO : EPOCH 4 - PROGRESS: at 37.68% examples, 461582 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:02,718 : INFO : EPOCH 4 - PROGRESS: at 44.83% examples, 479828 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:03,739 : INFO : EPOCH 4 - PROGRESS: at 51.50% examples, 490738 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:04,748 : INFO : EPOCH 4 - PROGRESS: at 58.07% examples, 498937 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:05,756 : INFO : EPOCH 4 - PROGRESS: at 64.73% examples, 506512 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:06,776 : INFO : EPOCH 4 - PROGRESS: at 70.82% examples, 508503 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:07,822 : INFO : EPOCH 4 - PROGRESS: at 77.29% examples, 510879 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:08,843 : INFO : EPOCH 4 - PROGRESS: at 84.15% examples, 516850 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:09,865 : INFO : EPOCH 4 - PROGRESS: at 90.63% examples, 519685 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:10,868 : INFO : EPOCH 4 - PROGRESS: at 97.97% examples, 526533 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:11,318 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-25 12:42:11,325 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 12:42:11,344 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 12:42:11,345 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 12:42:11,347 : INFO : EPOCH - 4 : training on 10346611 raw words (8854231 effective words) took 17.0s, 521721 effective words/s\n",
      "2018-05-25 12:42:12,504 : INFO : EPOCH 5 - PROGRESS: at 0.10% examples, 7679 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:13,510 : INFO : EPOCH 5 - PROGRESS: at 6.76% examples, 286917 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:14,511 : INFO : EPOCH 5 - PROGRESS: at 13.43% examples, 389870 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:15,515 : INFO : EPOCH 5 - PROGRESS: at 20.68% examples, 455259 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:16,525 : INFO : EPOCH 5 - PROGRESS: at 27.92% examples, 489937 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:17,537 : INFO : EPOCH 5 - PROGRESS: at 34.40% examples, 501344 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:18,539 : INFO : EPOCH 5 - PROGRESS: at 40.87% examples, 509778 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:19,542 : INFO : EPOCH 5 - PROGRESS: at 48.12% examples, 524303 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:20,546 : INFO : EPOCH 5 - PROGRESS: at 54.69% examples, 530387 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:21,555 : INFO : EPOCH 5 - PROGRESS: at 61.06% examples, 532905 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:22,556 : INFO : EPOCH 5 - PROGRESS: at 68.41% examples, 543564 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:23,576 : INFO : EPOCH 5 - PROGRESS: at 74.98% examples, 545057 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:24,594 : INFO : EPOCH 5 - PROGRESS: at 81.55% examples, 547305 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:42:25,594 : INFO : EPOCH 5 - PROGRESS: at 88.12% examples, 549545 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:26,602 : INFO : EPOCH 5 - PROGRESS: at 95.46% examples, 555492 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:27,409 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-25 12:42:27,441 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 12:42:27,445 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 12:42:27,452 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 12:42:27,453 : INFO : EPOCH - 5 : training on 10346611 raw words (8854562 effective words) took 16.1s, 549848 effective words/s\n",
      "2018-05-25 12:42:28,560 : INFO : EPOCH 6 - PROGRESS: at 0.10% examples, 8052 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:29,560 : INFO : EPOCH 6 - PROGRESS: at 6.57% examples, 286951 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:30,568 : INFO : EPOCH 6 - PROGRESS: at 13.24% examples, 391040 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:31,574 : INFO : EPOCH 6 - PROGRESS: at 20.58% examples, 458985 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:32,584 : INFO : EPOCH 6 - PROGRESS: at 28.02% examples, 496646 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:33,586 : INFO : EPOCH 6 - PROGRESS: at 34.20% examples, 503771 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:42:34,604 : INFO : EPOCH 6 - PROGRESS: at 40.48% examples, 508626 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:35,610 : INFO : EPOCH 6 - PROGRESS: at 46.38% examples, 508169 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:36,619 : INFO : EPOCH 6 - PROGRESS: at 52.56% examples, 512052 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:37,655 : INFO : EPOCH 6 - PROGRESS: at 58.36% examples, 510272 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:42:38,661 : INFO : EPOCH 6 - PROGRESS: at 64.44% examples, 512434 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-25 12:42:39,663 : INFO : EPOCH 6 - PROGRESS: at 70.72% examples, 516175 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:40,668 : INFO : EPOCH 6 - PROGRESS: at 78.07% examples, 525481 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:41,678 : INFO : EPOCH 6 - PROGRESS: at 84.54% examples, 528431 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:42,685 : INFO : EPOCH 6 - PROGRESS: at 91.59% examples, 534435 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:42:43,698 : INFO : EPOCH 6 - PROGRESS: at 97.97% examples, 534880 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:44,161 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-25 12:42:44,163 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 12:42:44,171 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 12:42:44,175 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 12:42:44,176 : INFO : EPOCH - 6 : training on 10346611 raw words (8855024 effective words) took 16.7s, 529760 effective words/s\n",
      "2018-05-25 12:42:45,339 : INFO : EPOCH 7 - PROGRESS: at 0.10% examples, 7652 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:46,349 : INFO : EPOCH 7 - PROGRESS: at 7.54% examples, 318899 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:47,368 : INFO : EPOCH 7 - PROGRESS: at 14.30% examples, 412119 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:48,383 : INFO : EPOCH 7 - PROGRESS: at 21.74% examples, 474533 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:49,392 : INFO : EPOCH 7 - PROGRESS: at 28.02% examples, 488335 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:50,409 : INFO : EPOCH 7 - PROGRESS: at 35.46% examples, 513073 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:51,410 : INFO : EPOCH 7 - PROGRESS: at 42.51% examples, 526041 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:52,414 : INFO : EPOCH 7 - PROGRESS: at 48.99% examples, 531256 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:53,421 : INFO : EPOCH 7 - PROGRESS: at 56.23% examples, 542740 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:54,428 : INFO : EPOCH 7 - PROGRESS: at 62.71% examples, 545118 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:55,432 : INFO : EPOCH 7 - PROGRESS: at 70.05% examples, 554531 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:56,436 : INFO : EPOCH 7 - PROGRESS: at 77.39% examples, 561404 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:57,448 : INFO : EPOCH 7 - PROGRESS: at 84.73% examples, 567651 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:58,458 : INFO : EPOCH 7 - PROGRESS: at 92.08% examples, 572947 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:42:59,653 : INFO : EPOCH 7 - PROGRESS: at 98.84% examples, 566170 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-25 12:42:59,791 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-25 12:42:59,803 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 12:42:59,815 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 12:42:59,818 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 12:42:59,820 : INFO : EPOCH - 7 : training on 10346611 raw words (8854927 effective words) took 15.6s, 566280 effective words/s\n",
      "2018-05-25 12:43:00,905 : INFO : EPOCH 8 - PROGRESS: at 0.10% examples, 8207 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:01,906 : INFO : EPOCH 8 - PROGRESS: at 7.44% examples, 327373 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:02,912 : INFO : EPOCH 8 - PROGRESS: at 14.78% examples, 439395 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:03,914 : INFO : EPOCH 8 - PROGRESS: at 22.13% examples, 495331 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:04,925 : INFO : EPOCH 8 - PROGRESS: at 29.28% examples, 520196 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:05,928 : INFO : EPOCH 8 - PROGRESS: at 35.75% examples, 527357 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:06,939 : INFO : EPOCH 8 - PROGRESS: at 43.09% examples, 541119 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:07,945 : INFO : EPOCH 8 - PROGRESS: at 48.89% examples, 537261 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:08,951 : INFO : EPOCH 8 - PROGRESS: at 55.17% examples, 539066 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:09,965 : INFO : EPOCH 8 - PROGRESS: at 62.03% examples, 544730 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:10,978 : INFO : EPOCH 8 - PROGRESS: at 69.37% examples, 553763 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:11,980 : INFO : EPOCH 8 - PROGRESS: at 76.62% examples, 560153 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:12,994 : INFO : EPOCH 8 - PROGRESS: at 83.29% examples, 561933 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:43:14,008 : INFO : EPOCH 8 - PROGRESS: at 90.53% examples, 566952 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:15,024 : INFO : EPOCH 8 - PROGRESS: at 98.07% examples, 571837 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:15,478 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-25 12:43:15,480 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 12:43:15,488 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 12:43:15,490 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 12:43:15,491 : INFO : EPOCH - 8 : training on 10346611 raw words (8854677 effective words) took 15.7s, 565144 effective words/s\n",
      "2018-05-25 12:43:16,573 : INFO : EPOCH 9 - PROGRESS: at 0.10% examples, 8227 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:17,583 : INFO : EPOCH 9 - PROGRESS: at 7.44% examples, 326622 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:18,599 : INFO : EPOCH 9 - PROGRESS: at 14.88% examples, 439974 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:19,606 : INFO : EPOCH 9 - PROGRESS: at 22.03% examples, 490907 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:20,617 : INFO : EPOCH 9 - PROGRESS: at 28.41% examples, 503388 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:21,620 : INFO : EPOCH 9 - PROGRESS: at 35.75% examples, 525719 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:22,636 : INFO : EPOCH 9 - PROGRESS: at 41.45% examples, 520087 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:23,640 : INFO : EPOCH 9 - PROGRESS: at 47.44% examples, 520054 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-25 12:43:24,643 : INFO : EPOCH 9 - PROGRESS: at 54.59% examples, 532314 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:25,674 : INFO : EPOCH 9 - PROGRESS: at 60.87% examples, 532629 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:26,686 : INFO : EPOCH 9 - PROGRESS: at 67.15% examples, 534356 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:27,692 : INFO : EPOCH 9 - PROGRESS: at 74.01% examples, 539612 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:28,694 : INFO : EPOCH 9 - PROGRESS: at 80.87% examples, 544641 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:29,706 : INFO : EPOCH 9 - PROGRESS: at 87.63% examples, 547862 words/s, in_qsize 8, out_qsize 0\n",
      "2018-05-25 12:43:30,717 : INFO : EPOCH 9 - PROGRESS: at 94.69% examples, 552337 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:31,630 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-25 12:43:31,642 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 12:43:31,658 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 12:43:31,660 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 12:43:31,661 : INFO : EPOCH - 9 : training on 10346611 raw words (8855476 effective words) took 16.2s, 547795 effective words/s\n",
      "2018-05-25 12:43:32,826 : INFO : EPOCH 10 - PROGRESS: at 0.10% examples, 7623 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:33,836 : INFO : EPOCH 10 - PROGRESS: at 7.44% examples, 314159 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:34,845 : INFO : EPOCH 10 - PROGRESS: at 14.78% examples, 426674 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:35,860 : INFO : EPOCH 10 - PROGRESS: at 22.13% examples, 483102 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:36,871 : INFO : EPOCH 10 - PROGRESS: at 29.47% examples, 513029 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:37,906 : INFO : EPOCH 10 - PROGRESS: at 34.88% examples, 503676 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:38,928 : INFO : EPOCH 10 - PROGRESS: at 41.93% examples, 516871 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:39,952 : INFO : EPOCH 10 - PROGRESS: at 49.28% examples, 530750 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:40,956 : INFO : EPOCH 10 - PROGRESS: at 56.52% examples, 542457 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:41,997 : INFO : EPOCH 10 - PROGRESS: at 63.77% examples, 549698 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:42,999 : INFO : EPOCH 10 - PROGRESS: at 69.37% examples, 545028 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:44,008 : INFO : EPOCH 10 - PROGRESS: at 76.62% examples, 551707 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:43:45,015 : INFO : EPOCH 10 - PROGRESS: at 83.19% examples, 553793 words/s, in_qsize 7, out_qsize 0\n",
      "2018-05-25 12:43:46,022 : INFO : EPOCH 10 - PROGRESS: at 88.70% examples, 548816 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:43:47,052 : INFO : EPOCH 10 - PROGRESS: at 95.46% examples, 550646 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-25 12:43:47,856 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-25 12:43:47,866 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 12:43:47,879 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 12:43:47,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 12:43:47,888 : INFO : EPOCH - 10 : training on 10346611 raw words (8854629 effective words) took 16.2s, 545840 effective words/s\n",
      "2018-05-25 12:43:47,888 : INFO : training on a 103466110 raw words (88546380 effective words) took 163.5s, 541633 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences, iter=10, min_count=20, size=300, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ve\n",
      "bir\n",
      "i\n",
      "da\n",
      "bu\n",
      "de\n",
      "için\n",
      "ile\n",
      "çok\n",
      "türkiye\n"
     ]
    }
   ],
   "source": [
    "# get top 10 most common words\n",
    "for i in range(10):\n",
    "    print(model.wv.index2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yidoğan\n",
      "şeküri\n",
      "kalınbağırsak\n",
      "gargara\n",
      "wen\n",
      "göğüste\n",
      "başvurulmalıdır\n",
      "intikamzamani\n",
      "kbb\n",
      "greenpeace\n"
     ]
    }
   ],
   "source": [
    "# get top 10 least common words\n",
    "vocab_size = len(model.wv.vocab)\n",
    "for i in range(1, 11):\n",
    "    print(model.wv.index2word[vocab_size - i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5309982688681165\n"
     ]
    }
   ],
   "source": [
    "# some similarity fun\n",
    "print(model.wv.similarity('erkek', 'kadın'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-25 12:44:04,590 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portakal\n"
     ]
    }
   ],
   "source": [
    "# what doesn't fit?\n",
    "print(model.wv.doesnt_match(\"kırmızı mavi portakal\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39233"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of words\n",
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dict for mapping words to index\n",
    "def word_to_index(string_data, wv):\n",
    "    index_data = {}\n",
    "    for word in string_data:\n",
    "        if word in wv:\n",
    "            index_data[word] = wv.vocab[word].index\n",
    "    return index_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_data = [x for x in open(path).read().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_2_index = word_to_index(str_data, model.wv)\n",
    "index_2_word = {k: v for v, k in word_2_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36222"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_2_index['uganda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uganda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_2_word[36222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb+') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"word2vec_data\"):\n",
    "    os.mkdir(\"word2vec_data\")\n",
    "\n",
    "save_obj(word_2_index, \"word2vec_data/word_2_index\")\n",
    "save_obj(index_2_word, \"word2vec_data/index_2_word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-25 12:45:27,034 : INFO : saving Word2Vec object under word2vec_data/my_word2vec, separately None\n",
      "2018-05-25 12:45:27,036 : INFO : storing np array 'vectors' to word2vec_data/my_word2vec.wv.vectors.npy\n",
      "2018-05-25 12:45:27,220 : INFO : not storing attribute vectors_norm\n",
      "2018-05-25 12:45:27,221 : INFO : storing np array 'syn1neg' to word2vec_data/my_word2vec.trainables.syn1neg.npy\n",
      "2018-05-25 12:45:27,255 : INFO : not storing attribute cum_table\n",
      "2018-05-25 12:45:27,339 : INFO : saved word2vec_data/my_word2vec\n"
     ]
    }
   ],
   "source": [
    "model.save(\"word2vec_data/my_word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the wv word vectors into a numpy matrix that is suitable for insertion\n",
    "# into TensorFlow or Keras models\n",
    "vector_dim = 300\n",
    "embedding_matrix = np.zeros((len(model.wv.vocab), vector_dim))\n",
    "for i in range(len(model.wv.vocab)):\n",
    "    embedding_vector = model.wv[model.wv.index2word[i]]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(file=\"word2vec_data/embeddings\", arr=embedding_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
