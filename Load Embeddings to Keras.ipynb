{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatih.barmanbay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\fatih.barmanbay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, merge\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.load(\"word2vec_data/embeddings.npy\")\n",
    "word_2_index = pickle.load(open('word2vec_data/word_2_index.pkl', 'rb'))\n",
    "index_2_word = pickle.load(open('word2vec_data/index_2_word.pkl', 'rb'))\n",
    "model = gensim.models.Word2Vec.load(\"word2vec_data/my_word2vec\")\n",
    "wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(v1, v2):\n",
    "    numerator = np.dot(v1, v2)\n",
    "    denominator = np.sqrt(np.sum(np.power(v1, 2))) * np.sqrt(np.sum(np.power(v2, 2)))\n",
    "    \n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(w1, w2):\n",
    "    idx1 = word_2_index[w1]\n",
    "    idx2 = word_2_index[w2]\n",
    "\n",
    "    v1 = embedding_matrix[idx1]\n",
    "    v2 = embedding_matrix[idx2]\n",
    "    return cos_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5155166151247436"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity(\"erkek\", \"kadın\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatih.barmanbay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\fatih.barmanbay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "# input words - in this case we do sample by sample evaluations of the similarity\n",
    "valid_word = Input((1,), dtype='int32')\n",
    "other_word = Input((1,), dtype='int32')\n",
    "\n",
    "# setup the embedding layer\n",
    "embeddings = Embedding(input_dim=embedding_matrix.shape[0], output_dim=embedding_matrix.shape[1],\n",
    "                      weights=[embedding_matrix])\n",
    "\n",
    "embedded_a = embeddings(valid_word)\n",
    "embedded_b = embeddings(other_word)\n",
    "similarity = merge([embedded_a, embedded_b], mode='cos', dot_axes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Keras model\n",
    "k_model = Model(inputs=[valid_word, other_word], outputs=similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(valid_word_idx, vocab_size):\n",
    "    sim = np.zeros((vocab_size,))\n",
    "    in_arr1 = np.zeros((1,))\n",
    "    in_arr2 = np.zeros((1,))\n",
    "    in_arr1[0,] = valid_word_idx\n",
    "    for i in range(vocab_size):\n",
    "        in_arr2[0,] = i\n",
    "        out = k_model.predict_on_batch([in_arr1, in_arr2])\n",
    "        sim[i] = out\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 15  # Random set of words to evaluate similarity on.\n",
    "valid_window = 250  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to 'ki': nsanlar, nanılmaz, nşallah, nsanların, şin, kisi, sterse, şe,\n",
      "Nearest to 'o': dediğiniz, oynadığım, onlar, bu, dediğim, öyle, istediğin, binnur,\n",
      "Nearest to 'takım': takımın, takımımız, takımda, ekip, takımlar, takımımızın, takıma, takımı,\n",
      "Nearest to 'şey': şeyi, birşey, şeyler, şeyimiz, şeyim, şeyin, şeye, şeyde,\n",
      "Nearest to 'geldi': gelmişti, gelirken, gelmiştir, geliyor, geldik, gelebilir, geldiler, gelen,\n",
      "Nearest to 'bunun': onun, bunların, düşeni, bunu, sözünün, denmesi, öğrenmesi, sorması,\n",
      "Nearest to 'diye': şeklinde, diyerek, deyip, neyi, sözleriyle, bilmediğim, yoksa, dedim,\n",
      "Nearest to 'çıktı': çıkmıştı, çıkarıldı, çıkıyor, atılmıştı, çıkmıştır, çıkan, çıkınca, çıkarken,\n",
      "Nearest to 'hem': hemde, kulübüm, kültürle, rahatlatmak, stattaki, kalitesini, gelişmesine, başarısıyla,\n",
      "Nearest to '12': 17, 22, 15, 14, 11, 7, 18, 27,\n",
      "Nearest to 'beşiktaş': galatasaray, bursaspor, fenerbahçe, niang, trabzonspor, sivasspor, eskişehirspor, ktaş,\n",
      "Nearest to 'neden': sebep, şahit, fırsatım, habercisi, şikâyetçi, faydası, telef, engel,\n",
      "Nearest to 'gelen': gelebilecek, gelirken, gelmişti, gelerek, geldiğini, geldi, geliyor, gelmektedir,\n",
      "Nearest to 'i': geçmi, konsolosu, yari, hi, sirada, güngörenspor, mse, lo,\n",
      "Nearest to 'daki': da, dayken, daydı, merkezli, dan, sokaklarında, yakasında, kıtasının,\n"
     ]
    }
   ],
   "source": [
    "# now run the model and get the closest words to the valid examples\n",
    "for i in range(valid_size):\n",
    "    valid_word = index_2_word[valid_examples[i]]\n",
    "    top_k = 8  # number of nearest neighbors\n",
    "    sim = get_sim(valid_examples[i], len(wv.vocab))\n",
    "    nearest = (-sim).argsort()[1:top_k + 1]\n",
    "    log_str = \"Nearest to '%s':\" % valid_word\n",
    "    for k in range(top_k):\n",
    "        close_word = index_2_word[nearest[k]]\n",
    "        log_str = '%s %s,' % (log_str, close_word)\n",
    "    print(log_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
