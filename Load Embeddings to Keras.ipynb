{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, merge\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.load(\"word2vec_data/embeddings.npy\")\n",
    "word_2_index = pickle.load(open('word2vec_data/word_2_index.pkl', 'rb'))\n",
    "index_2_word = pickle.load(open('word2vec_data/index_2_word.pkl', 'rb'))\n",
    "model = gensim.models.Word2Vec.load(\"word2vec_data/my_word2vec\")\n",
    "wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_similarity(v1, v2):\n",
    "    numerator = np.dot(v1, v2)\n",
    "    denominator = np.sqrt(np.sum(np.power(v1, 2))) * np.sqrt(np.sum(np.power(v2, 2)))\n",
    "    \n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_similarity(w1, w2):\n",
    "    idx1 = word_2_index[w1]\n",
    "    idx2 = word_2_index[w2]\n",
    "\n",
    "    v1 = embedding_matrix[idx1]\n",
    "    v2 = embedding_matrix[idx2]\n",
    "    return cos_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5309982688681166"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity(\"erkek\", \"kadın\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exastax/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/exastax/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:464: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "# input words - in this case we do sample by sample evaluations of the similarity\n",
    "valid_word = Input((1,), dtype='int32')\n",
    "other_word = Input((1,), dtype='int32')\n",
    "\n",
    "# setup the embedding layer\n",
    "embeddings = Embedding(input_dim=embedding_matrix.shape[0], output_dim=embedding_matrix.shape[1],\n",
    "                      weights=[embedding_matrix])\n",
    "\n",
    "embedded_a = embeddings(valid_word)\n",
    "embedded_b = embeddings(other_word)\n",
    "similarity = merge([embedded_a, embedded_b], mode='cos', dot_axes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the Keras model\n",
    "k_model = Model(inputs=[valid_word, other_word], outputs=similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sim(valid_word_idx, vocab_size):\n",
    "    sim = np.zeros((vocab_size,))\n",
    "    in_arr1 = np.zeros((1,))\n",
    "    in_arr2 = np.zeros((1,))\n",
    "    in_arr1[0,] = valid_word_idx\n",
    "    for i in range(vocab_size):\n",
    "        in_arr2[0,] = i\n",
    "        out = k_model.predict_on_batch([in_arr1, in_arr2])\n",
    "        sim[i] = out\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_size = 15  # Random set of words to evaluate similarity on.\n",
    "valid_window = 250  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to 'fazla': az, fazlası, fazlasını, fazladır, fazlasının, pahalı, ucuza, fazlasına,\n",
      "Nearest to 'ortaya': karşımıza, açığa, görücüye, sandıktan, çileden, karşıma, ava, karşılarına,\n",
      "Nearest to 'a': la, ın, ına, tan, takımına, lara, ı, kentine,\n",
      "Nearest to 'önce': evvel, önceden, öncede, dolmadan, süreyle, önceki, öncesinden, sonraya,\n",
      "Nearest to 'futbol': basketbol, voleybol, briç, a2, tenis, u15, ragbi, futbolu,\n",
      "Nearest to '11': 12, 21, 18, 14, 17, 9, 8, 15,\n",
      "Nearest to 'alan': almıştı, alacak, alıyor, aldı, aldığı, alıyordu, alırken, alarak,\n",
      "Nearest to 'ayrıca': örneğin, bulunacağı, böylece, kolaylığı, listeleri, zira, değiştirildiği, tavsiyeler,\n",
      "Nearest to 'sonra': sonrada, sonraki, dolmadan, öncede, önce, itibaren, önceden, sonrasını,\n",
      "Nearest to 'bunu': bunları, şunu, onu, doğruyu, onları, işimizi, gereğini, zoru,\n",
      "Nearest to 'e': ten, ine, in, le, teki, lere, kilograma, bine,\n",
      "Nearest to 'söz': alay, merak, şikayet, eleştiri, tartışma, polemik, sözkonusu, itibar,\n",
      "Nearest to 'aynı': arta, ayni, yakın, eşit, yaşadıklarına, sorunsuz, bu, benzer,\n",
      "Nearest to 'bugün': yarın, dün, akşam, bugünkü, netice, sabah, şimdi, günü,\n",
      "Nearest to 'türk': alman, yunan, amerikan, arnavut, bulgar, rus, ermeni, yöre,\n"
     ]
    }
   ],
   "source": [
    "# now run the model and get the closest words to the valid examples\n",
    "for i in range(valid_size):\n",
    "    valid_word = index_2_word[valid_examples[i]]\n",
    "    top_k = 8  # number of nearest neighbors\n",
    "    sim = get_sim(valid_examples[i], len(wv.vocab))\n",
    "    nearest = (-sim).argsort()[1:top_k + 1]\n",
    "    log_str = \"Nearest to '%s':\" % valid_word\n",
    "    for k in range(top_k):\n",
    "        close_word = index_2_word[nearest[k]]\n",
    "        log_str = '%s %s,' % (log_str, close_word)\n",
    "    print(log_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
