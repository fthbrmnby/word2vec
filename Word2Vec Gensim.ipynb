{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatih.barmanbay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence(object):\n",
    "    \"\"\" Setup an iterator which cycle through the data \n",
    "    without having to load the entire data set into memory.\n",
    "    This is vital, as some text data sets are huge \"\"\"\n",
    "    \n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for file_name in os.listdir(self.dirname):\n",
    "            with open(os.path.join(self.dirname, file_name), 'r') as f:\n",
    "                for word in f.read().split():\n",
    "                    yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = word2vec.Text8Corpus('text')\n",
    "path = \"processed_text_data/text\"\n",
    "sentences = word2vec.LineSentence(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-05 10:33:51,334 : INFO : collecting all words and their counts\n",
      "2018-06-05 10:33:54,431 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-06-05 10:33:59,436 : INFO : collected 302084 word types from a corpus of 10346611 raw words and 1035 sentences\n",
      "2018-06-05 10:33:59,438 : INFO : Loading a fresh vocabulary\n",
      "2018-06-05 10:33:59,758 : INFO : min_count=20 retains 39233 unique words (12% of original 302084, drops 262851)\n",
      "2018-06-05 10:33:59,759 : INFO : min_count=20 leaves 9432604 word corpus (91% of original 10346611, drops 914007)\n",
      "2018-06-05 10:33:59,967 : INFO : deleting the raw counts dictionary of 302084 items\n",
      "2018-06-05 10:34:00,163 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2018-06-05 10:34:00,165 : INFO : downsampling leaves estimated 8854970 word corpus (93.9% of prior 9432604)\n",
      "2018-06-05 10:34:00,377 : INFO : estimated required memory for 39233 words and 300 dimensions: 113775700 bytes\n",
      "2018-06-05 10:34:00,379 : INFO : resetting layer weights\n",
      "2018-06-05 10:34:01,503 : INFO : training model with 4 workers on 39233 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-06-05 10:34:04,580 : INFO : EPOCH 1 - PROGRESS: at 0.10% examples, 2776 words/s, in_qsize 6, out_qsize 1\n",
      "2018-06-05 10:34:05,591 : INFO : EPOCH 1 - PROGRESS: at 6.47% examples, 140552 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:06,607 : INFO : EPOCH 1 - PROGRESS: at 12.75% examples, 222103 words/s, in_qsize 7, out_qsize 1\n",
      "2018-06-05 10:34:07,623 : INFO : EPOCH 1 - PROGRESS: at 19.23% examples, 279013 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:08,630 : INFO : EPOCH 1 - PROGRESS: at 25.51% examples, 316381 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:09,643 : INFO : EPOCH 1 - PROGRESS: at 31.79% examples, 344796 words/s, in_qsize 8, out_qsize 1\n",
      "2018-06-05 10:34:10,645 : INFO : EPOCH 1 - PROGRESS: at 38.16% examples, 368206 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:11,683 : INFO : EPOCH 1 - PROGRESS: at 44.54% examples, 386528 words/s, in_qsize 7, out_qsize 1\n",
      "2018-06-05 10:34:12,711 : INFO : EPOCH 1 - PROGRESS: at 51.11% examples, 401974 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:13,737 : INFO : EPOCH 1 - PROGRESS: at 57.68% examples, 414432 words/s, in_qsize 7, out_qsize 1\n",
      "2018-06-05 10:34:14,738 : INFO : EPOCH 1 - PROGRESS: at 64.15% examples, 424990 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:15,745 : INFO : EPOCH 1 - PROGRESS: at 70.53% examples, 434278 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:16,747 : INFO : EPOCH 1 - PROGRESS: at 76.81% examples, 443456 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:17,758 : INFO : EPOCH 1 - PROGRESS: at 82.80% examples, 449543 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:18,792 : INFO : EPOCH 1 - PROGRESS: at 89.18% examples, 456635 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:19,800 : INFO : EPOCH 1 - PROGRESS: at 95.46% examples, 462204 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:20,811 : INFO : EPOCH 1 - PROGRESS: at 98.84% examples, 453632 words/s, in_qsize 5, out_qsize 2\n",
      "2018-06-05 10:34:20,944 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-05 10:34:20,963 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-05 10:34:20,965 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-05 10:34:20,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-05 10:34:20,977 : INFO : EPOCH - 1 : training on 10346611 raw words (8855307 effective words) took 19.5s, 454876 effective words/s\n",
      "2018-06-05 10:34:23,936 : INFO : EPOCH 2 - PROGRESS: at 0.10% examples, 2873 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:24,961 : INFO : EPOCH 2 - PROGRESS: at 6.18% examples, 137602 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:25,987 : INFO : EPOCH 2 - PROGRESS: at 12.08% examples, 214120 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:27,011 : INFO : EPOCH 2 - PROGRESS: at 18.36% examples, 270292 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:28,013 : INFO : EPOCH 2 - PROGRESS: at 24.83% examples, 312118 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:29,023 : INFO : EPOCH 2 - PROGRESS: at 31.11% examples, 341261 words/s, in_qsize 6, out_qsize 1\n",
      "2018-06-05 10:34:30,045 : INFO : EPOCH 2 - PROGRESS: at 37.58% examples, 365344 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:31,049 : INFO : EPOCH 2 - PROGRESS: at 43.67% examples, 382845 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:32,067 : INFO : EPOCH 2 - PROGRESS: at 49.86% examples, 396723 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:33,072 : INFO : EPOCH 2 - PROGRESS: at 56.23% examples, 408614 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:34,074 : INFO : EPOCH 2 - PROGRESS: at 62.32% examples, 417566 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:35,081 : INFO : EPOCH 2 - PROGRESS: at 68.79% examples, 427595 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:36,088 : INFO : EPOCH 2 - PROGRESS: at 74.88% examples, 435648 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:37,102 : INFO : EPOCH 2 - PROGRESS: at 81.06% examples, 443210 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:38,113 : INFO : EPOCH 2 - PROGRESS: at 87.34% examples, 450826 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:39,121 : INFO : EPOCH 2 - PROGRESS: at 93.53% examples, 456631 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:40,484 : INFO : EPOCH 2 - PROGRESS: at 98.84% examples, 448931 words/s, in_qsize 8, out_qsize 2\n",
      "2018-06-05 10:34:40,615 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-05 10:34:40,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-05 10:34:40,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-05 10:34:40,644 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-05 10:34:40,646 : INFO : EPOCH - 2 : training on 10346611 raw words (8854532 effective words) took 19.7s, 450284 effective words/s\n",
      "2018-06-05 10:34:43,740 : INFO : EPOCH 3 - PROGRESS: at 0.10% examples, 2766 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:44,760 : INFO : EPOCH 3 - PROGRESS: at 6.76% examples, 145995 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:45,787 : INFO : EPOCH 3 - PROGRESS: at 13.43% examples, 232304 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:46,826 : INFO : EPOCH 3 - PROGRESS: at 19.81% examples, 284556 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:47,838 : INFO : EPOCH 3 - PROGRESS: at 26.09% examples, 320512 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:48,847 : INFO : EPOCH 3 - PROGRESS: at 32.46% examples, 349472 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:49,848 : INFO : EPOCH 3 - PROGRESS: at 39.13% examples, 375174 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:50,851 : INFO : EPOCH 3 - PROGRESS: at 45.60% examples, 394812 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:34:51,854 : INFO : EPOCH 3 - PROGRESS: at 52.46% examples, 412064 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:52,857 : INFO : EPOCH 3 - PROGRESS: at 58.94% examples, 424160 words/s, in_qsize 8, out_qsize 1\n",
      "2018-06-05 10:34:53,876 : INFO : EPOCH 3 - PROGRESS: at 65.70% examples, 435300 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:54,878 : INFO : EPOCH 3 - PROGRESS: at 72.08% examples, 444495 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:55,882 : INFO : EPOCH 3 - PROGRESS: at 81.06% examples, 469118 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:56,882 : INFO : EPOCH 3 - PROGRESS: at 90.92% examples, 495981 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:34:57,935 : INFO : EPOCH 3 - PROGRESS: at 98.84% examples, 506561 words/s, in_qsize 8, out_qsize 1\n",
      "2018-06-05 10:34:58,017 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-05 10:34:58,028 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-05 10:34:58,035 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-05 10:34:58,036 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-05 10:34:58,036 : INFO : EPOCH - 3 : training on 10346611 raw words (8854435 effective words) took 17.4s, 509315 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-05 10:34:59,361 : INFO : EPOCH 4 - PROGRESS: at 0.10% examples, 6449 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:00,375 : INFO : EPOCH 4 - PROGRESS: at 10.14% examples, 385619 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:01,377 : INFO : EPOCH 4 - PROGRESS: at 19.23% examples, 510913 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:02,378 : INFO : EPOCH 4 - PROGRESS: at 28.21% examples, 573686 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:03,387 : INFO : EPOCH 4 - PROGRESS: at 38.16% examples, 628986 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:04,392 : INFO : EPOCH 4 - PROGRESS: at 47.34% examples, 658006 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:05,398 : INFO : EPOCH 4 - PROGRESS: at 57.29% examples, 683981 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:06,404 : INFO : EPOCH 4 - PROGRESS: at 67.44% examples, 706555 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:07,404 : INFO : EPOCH 4 - PROGRESS: at 77.49% examples, 728073 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:08,405 : INFO : EPOCH 4 - PROGRESS: at 87.44% examples, 745915 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:09,412 : INFO : EPOCH 4 - PROGRESS: at 96.62% examples, 752432 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:09,971 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-05 10:35:09,983 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-05 10:35:09,984 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-05 10:35:09,985 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-05 10:35:09,985 : INFO : EPOCH - 4 : training on 10346611 raw words (8854919 effective words) took 11.9s, 741205 effective words/s\n",
      "2018-06-05 10:35:11,340 : INFO : EPOCH 5 - PROGRESS: at 0.10% examples, 6318 words/s, in_qsize 6, out_qsize 1\n",
      "2018-06-05 10:35:12,343 : INFO : EPOCH 5 - PROGRESS: at 10.34% examples, 389798 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:13,348 : INFO : EPOCH 5 - PROGRESS: at 20.48% examples, 540247 words/s, in_qsize 8, out_qsize 1\n",
      "2018-06-05 10:35:14,359 : INFO : EPOCH 5 - PROGRESS: at 30.53% examples, 616268 words/s, in_qsize 6, out_qsize 1\n",
      "2018-06-05 10:35:15,374 : INFO : EPOCH 5 - PROGRESS: at 40.58% examples, 664625 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:16,375 : INFO : EPOCH 5 - PROGRESS: at 50.63% examples, 698665 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:17,376 : INFO : EPOCH 5 - PROGRESS: at 60.68% examples, 721143 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:18,386 : INFO : EPOCH 5 - PROGRESS: at 71.01% examples, 741276 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:19,387 : INFO : EPOCH 5 - PROGRESS: at 79.81% examples, 748014 words/s, in_qsize 8, out_qsize 1\n",
      "2018-06-05 10:35:20,387 : INFO : EPOCH 5 - PROGRESS: at 89.28% examples, 759717 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:21,635 : INFO : EPOCH 5 - PROGRESS: at 98.84% examples, 751759 words/s, in_qsize 4, out_qsize 3\n",
      "2018-06-05 10:35:21,719 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-05 10:35:21,728 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-05 10:35:21,733 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-05 10:35:21,735 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-05 10:35:21,736 : INFO : EPOCH - 5 : training on 10346611 raw words (8854706 effective words) took 11.7s, 753739 effective words/s\n",
      "2018-06-05 10:35:23,075 : INFO : EPOCH 6 - PROGRESS: at 0.10% examples, 6379 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:24,087 : INFO : EPOCH 6 - PROGRESS: at 10.43% examples, 394472 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:25,103 : INFO : EPOCH 6 - PROGRESS: at 20.00% examples, 527373 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:26,104 : INFO : EPOCH 6 - PROGRESS: at 29.28% examples, 591669 words/s, in_qsize 8, out_qsize 1\n",
      "2018-06-05 10:35:27,105 : INFO : EPOCH 6 - PROGRESS: at 39.32% examples, 646019 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:28,114 : INFO : EPOCH 6 - PROGRESS: at 48.50% examples, 671806 words/s, in_qsize 6, out_qsize 1\n",
      "2018-06-05 10:35:29,125 : INFO : EPOCH 6 - PROGRESS: at 58.07% examples, 690662 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:30,135 : INFO : EPOCH 6 - PROGRESS: at 68.12% examples, 710915 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:31,138 : INFO : EPOCH 6 - PROGRESS: at 78.16% examples, 732030 words/s, in_qsize 6, out_qsize 1\n",
      "2018-06-05 10:35:32,144 : INFO : EPOCH 6 - PROGRESS: at 88.31% examples, 750762 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:33,147 : INFO : EPOCH 6 - PROGRESS: at 98.65% examples, 765965 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:33,553 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-05 10:35:33,558 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-05 10:35:33,561 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-05 10:35:33,575 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-05 10:35:33,576 : INFO : EPOCH - 6 : training on 10346611 raw words (8854991 effective words) took 11.8s, 748053 effective words/s\n",
      "2018-06-05 10:35:34,928 : INFO : EPOCH 7 - PROGRESS: at 0.10% examples, 6301 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:35,932 : INFO : EPOCH 7 - PROGRESS: at 9.28% examples, 349648 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:36,933 : INFO : EPOCH 7 - PROGRESS: at 19.52% examples, 515943 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:37,936 : INFO : EPOCH 7 - PROGRESS: at 29.57% examples, 598455 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:38,952 : INFO : EPOCH 7 - PROGRESS: at 39.81% examples, 653174 words/s, in_qsize 8, out_qsize 1\n",
      "2018-06-05 10:35:39,967 : INFO : EPOCH 7 - PROGRESS: at 49.66% examples, 685727 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:40,978 : INFO : EPOCH 7 - PROGRESS: at 58.84% examples, 698385 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:41,994 : INFO : EPOCH 7 - PROGRESS: at 69.28% examples, 721437 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:43,008 : INFO : EPOCH 7 - PROGRESS: at 79.61% examples, 743662 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:44,012 : INFO : EPOCH 7 - PROGRESS: at 89.76% examples, 761332 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:45,169 : INFO : EPOCH 7 - PROGRESS: at 98.94% examples, 756097 words/s, in_qsize 5, out_qsize 2\n",
      "2018-06-05 10:35:45,246 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-05 10:35:45,254 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-05 10:35:45,261 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-05 10:35:45,266 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-05 10:35:45,267 : INFO : EPOCH - 7 : training on 10346611 raw words (8854723 effective words) took 11.7s, 757553 effective words/s\n",
      "2018-06-05 10:35:46,573 : INFO : EPOCH 8 - PROGRESS: at 0.10% examples, 6532 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:47,581 : INFO : EPOCH 8 - PROGRESS: at 10.34% examples, 397354 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:48,582 : INFO : EPOCH 8 - PROGRESS: at 20.58% examples, 550793 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:49,587 : INFO : EPOCH 8 - PROGRESS: at 30.72% examples, 628005 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:50,588 : INFO : EPOCH 8 - PROGRESS: at 40.87% examples, 678238 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:51,602 : INFO : EPOCH 8 - PROGRESS: at 51.01% examples, 709851 words/s, in_qsize 6, out_qsize 1\n",
      "2018-06-05 10:35:52,605 : INFO : EPOCH 8 - PROGRESS: at 60.19% examples, 720830 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:53,609 : INFO : EPOCH 8 - PROGRESS: at 69.76% examples, 733285 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:35:54,617 : INFO : EPOCH 8 - PROGRESS: at 80.00% examples, 754125 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:55,650 : INFO : EPOCH 8 - PROGRESS: at 90.05% examples, 767882 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:35:56,859 : INFO : EPOCH 8 - PROGRESS: at 98.84% examples, 755531 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-05 10:35:56,942 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-05 10:35:56,952 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-05 10:35:56,964 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-05 10:35:56,966 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-05 10:35:56,966 : INFO : EPOCH - 8 : training on 10346611 raw words (8854762 effective words) took 11.7s, 757124 effective words/s\n",
      "2018-06-05 10:35:58,322 : INFO : EPOCH 9 - PROGRESS: at 0.10% examples, 6307 words/s, in_qsize 8, out_qsize 1\n",
      "2018-06-05 10:35:59,327 : INFO : EPOCH 9 - PROGRESS: at 9.76% examples, 367224 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:36:00,339 : INFO : EPOCH 9 - PROGRESS: at 19.90% examples, 523940 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:36:01,344 : INFO : EPOCH 9 - PROGRESS: at 30.05% examples, 605733 words/s, in_qsize 8, out_qsize 1\n",
      "2018-06-05 10:36:02,347 : INFO : EPOCH 9 - PROGRESS: at 40.19% examples, 658952 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:36:03,361 : INFO : EPOCH 9 - PROGRESS: at 49.57% examples, 684067 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:36:04,370 : INFO : EPOCH 9 - PROGRESS: at 59.90% examples, 710869 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:36:05,381 : INFO : EPOCH 9 - PROGRESS: at 70.24% examples, 731810 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:36:06,382 : INFO : EPOCH 9 - PROGRESS: at 79.71% examples, 745906 words/s, in_qsize 8, out_qsize 1\n",
      "2018-06-05 10:36:07,389 : INFO : EPOCH 9 - PROGRESS: at 89.76% examples, 762370 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:36:08,541 : INFO : EPOCH 9 - PROGRESS: at 98.84% examples, 756574 words/s, in_qsize 4, out_qsize 3\n",
      "2018-06-05 10:36:08,623 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-05 10:36:08,636 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-05 10:36:08,639 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-05 10:36:08,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-05 10:36:08,641 : INFO : EPOCH - 9 : training on 10346611 raw words (8854924 effective words) took 11.7s, 758549 effective words/s\n",
      "2018-06-05 10:36:09,951 : INFO : EPOCH 10 - PROGRESS: at 0.10% examples, 6515 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:36:10,959 : INFO : EPOCH 10 - PROGRESS: at 10.43% examples, 400383 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:36:11,962 : INFO : EPOCH 10 - PROGRESS: at 20.39% examples, 545052 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:36:12,974 : INFO : EPOCH 10 - PROGRESS: at 30.34% examples, 618371 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:36:13,979 : INFO : EPOCH 10 - PROGRESS: at 39.52% examples, 653286 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:36:14,980 : INFO : EPOCH 10 - PROGRESS: at 49.66% examples, 691703 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:36:15,987 : INFO : EPOCH 10 - PROGRESS: at 59.90% examples, 716749 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:36:16,990 : INFO : EPOCH 10 - PROGRESS: at 69.95% examples, 734796 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-05 10:36:17,997 : INFO : EPOCH 10 - PROGRESS: at 79.61% examples, 749971 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:36:19,001 : INFO : EPOCH 10 - PROGRESS: at 89.76% examples, 767254 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-05 10:36:20,173 : INFO : EPOCH 10 - PROGRESS: at 98.84% examples, 759539 words/s, in_qsize 8, out_qsize 2\n",
      "2018-06-05 10:36:20,263 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-05 10:36:20,270 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-05 10:36:20,271 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-05 10:36:20,273 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-05 10:36:20,274 : INFO : EPOCH - 10 : training on 10346611 raw words (8855707 effective words) took 11.6s, 761527 effective words/s\n",
      "2018-06-05 10:36:20,274 : INFO : training on a 103466110 raw words (88549006 effective words) took 138.8s, 638099 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences, iter=10, min_count=20, size=300, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ve\n",
      "bir\n",
      "i\n",
      "da\n",
      "bu\n",
      "de\n",
      "için\n",
      "ile\n",
      "çok\n",
      "türkiye\n"
     ]
    }
   ],
   "source": [
    "# get top 10 most common words\n",
    "for i in range(10):\n",
    "    print(model.wv.index2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yidoğan\n",
      "şikesi\n",
      "buducnost\n",
      "gallinari\n",
      "eurochallenge\n",
      "ea7\n",
      "rajon\n",
      "lowdon\n",
      "amachree\n",
      "sakatlığından\n"
     ]
    }
   ],
   "source": [
    "# get top 10 least common words\n",
    "vocab_size = len(model.wv.vocab)\n",
    "for i in range(1, 11):\n",
    "    print(model.wv.index2word[vocab_size - i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5929566350028003\n"
     ]
    }
   ],
   "source": [
    "# some similarity fun\n",
    "print(model.wv.similarity('portakal', 'elma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-05 10:37:31,454 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portakal\n"
     ]
    }
   ],
   "source": [
    "# what doesn't fit?\n",
    "print(model.wv.doesnt_match(\"kırmızı mavi portakal\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('center', 0.5331943035125732), ('halkalı', 0.4877026081085205), ('cnr', 0.477074533700943), ('sofya', 0.4761894643306732), ('garden', 0.47203749418258667), ('barselona', 0.4646550714969635), ('plaza', 0.4631446599960327), ('sheraton', 0.46216270327568054), ('contemporary', 0.4611188769340515), ('mudanya', 0.46009308099746704)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=[\"istanbul\", \"ankara\"], negative=[\"erkek\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39233"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of words\n",
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict for mapping words to index\n",
    "def word_to_index(string_data, wv):\n",
    "    index_data = {}\n",
    "    for word in string_data:\n",
    "        if word in wv:\n",
    "            index_data[word] = wv.vocab[word].index\n",
    "    return index_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_data = [x for x in open(path, encoding=\"utf-8\").read().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_index = word_to_index(str_data, model.wv)\n",
    "index_2_word = {k: v for v, k in word_2_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36084"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_2_index['uganda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uganda'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_2_word[36084]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb+') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"word2vec_data\"):\n",
    "    os.mkdir(\"word2vec_data\")\n",
    "\n",
    "save_obj(word_2_index, \"word2vec_data/word_2_index\")\n",
    "save_obj(index_2_word, \"word2vec_data/index_2_word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-05 10:43:32,611 : INFO : saving Word2Vec object under word2vec_data/my_word2vec, separately None\n",
      "2018-06-05 10:43:32,612 : INFO : storing np array 'vectors' to word2vec_data/my_word2vec.wv.vectors.npy\n",
      "2018-06-05 10:43:32,725 : INFO : not storing attribute vectors_norm\n",
      "2018-06-05 10:43:32,726 : INFO : storing np array 'syn1neg' to word2vec_data/my_word2vec.trainables.syn1neg.npy\n",
      "2018-06-05 10:43:32,836 : INFO : not storing attribute cum_table\n",
      "2018-06-05 10:43:32,915 : INFO : saved word2vec_data/my_word2vec\n"
     ]
    }
   ],
   "source": [
    "model.save(\"word2vec_data/my_word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the wv word vectors into a numpy matrix that is suitable for insertion\n",
    "# into TensorFlow or Keras models\n",
    "vector_dim = 300\n",
    "embedding_matrix = np.zeros((len(model.wv.vocab), vector_dim))\n",
    "for i in range(len(model.wv.vocab)):\n",
    "    embedding_vector = model.wv[model.wv.index2word[i]]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=\"word2vec_data/embeddings\", arr=embedding_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
